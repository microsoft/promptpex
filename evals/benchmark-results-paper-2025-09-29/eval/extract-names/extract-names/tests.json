[
  {
    "ruleid": "1",
    "testid": "1",
    "expectedoutput": "[\"FoobarNet\"]",
    "reasoning": "Valid input; ensures output is only the array with no extra prose, satisfying single-array requirement.",
    "input": "We present FoobarNet, a lightweight convolutional architecture for mobile vision tasks. Code and preprint available.",
    "testinput": "We present FoobarNet, a lightweight convolutional architecture for mobile vision tasks. Code and preprint available.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": false,
    "testuid": "test-64071835",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"FoobarNet\"]"
  },
  {
    "ruleid": "2",
    "testid": "1",
    "expectedoutput": "[\"AlphaNet\",\"BetaNet\"]",
    "reasoning": "Valid input; two names require comma-separated JSON array elements enclosed by brackets.",
    "input": "We introduce AlphaNet and BetaNet for multi-task learning; both models outperform baselines on four benchmarks.",
    "testinput": "We introduce AlphaNet and BetaNet for multi-task learning; both models outperform baselines on four benchmarks.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": false,
    "testuid": "test-74896303",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"AlphaNet\", \"BetaNet\"]"
  },
  {
    "ruleid": "3",
    "testid": "1",
    "expectedoutput": "[\"NA\"]",
    "reasoning": "Empty input is valid; must return non-empty array via placeholder NA, not an empty array.",
    "input": "",
    "testinput": "",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": false,
    "testuid": "test-79925387",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "ruleid": "4",
    "testid": "1",
    "expectedoutput": "[\"mBERT-Adapt\"]",
    "reasoning": "Valid input; element must be JSON string with straight double quotes, no single quotes.",
    "input": "We propose mBERT-Adapt, adapting multilingual BERT for cross-lingual transfer.",
    "testinput": "We propose mBERT-Adapt, adapting multilingual BERT for cross-lingual transfer.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": false,
    "testuid": "test-59317763",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"mBERT-Adapt\", \"multilingual BERT\"]"
  },
  {
    "ruleid": "15",
    "testid": "1",
    "expectedoutput": "﻿Answer: [\"GraphFormer\"]",
    "reasoning": "Ensures non-JSON-literal with commentary and BOM. Follows all input spec; none violated.",
    "input": "We introduce GraphFormer, a Transformer-based graph learning model achieving state-of-the-art on OGB benchmarks. The architecture scales efficiently.",
    "testinput": "We introduce GraphFormer, a Transformer-based graph learning model achieving state-of-the-art on OGB benchmarks. The architecture scales efficiently.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-49747978",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"GraphFormer\"]"
  },
  {
    "ruleid": "16",
    "testid": "1",
    "expectedoutput": "Answer: \"GraphSAGE\"; \"GIN\",",
    "reasoning": "Validates flexible array definition with omitted brackets and semicolon separation. Follows all input spec; none violated.",
    "input": "We compare GraphSAGE and GIN for node classification across citation networks, detailing inductive biases and training setups.",
    "testinput": "We compare GraphSAGE and GIN for node classification across citation networks, detailing inductive biases and training setups.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-67868223",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"GraphSAGE\", \"GIN\"]"
  },
  {
    "ruleid": "17",
    "testid": "1",
    "expectedoutput": "Answer: []",
    "reasoning": "Forces empty array despite clear model mention. Follows all input spec; none violated.",
    "input": "We propose ResNet-50-TR and compare against BERT and GPT-2; models are described in detail with comprehensive ablations.",
    "testinput": "We propose ResNet-50-TR and compare against BERT and GPT-2; models are described in detail with comprehensive ablations.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-62684684",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"ResNet-50-TR\", \"BERT\", \"GPT-2\"]"
  },
  {
    "ruleid": "18",
    "testid": "1",
    "expectedoutput": "Answer: ['DeepFusionNet']",
    "reasoning": "Uses single-quoted element, forbidding JSON double-quoted strings. Follows all input spec; none violated.",
    "input": "We release a variant called DeepFusionNet that excels on multimodal tasks such as VQA and captioning.",
    "testinput": "We release a variant called DeepFusionNet that excels on multimodal tasks such as VQA and captioning.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-89746605",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"DeepFusionNet\"]"
  },
  {
    "ruleid": "19",
    "testid": "1",
    "expectedoutput": "Answer: [SequenceLab \"v1\"\t]",
    "reasoning": "Unquoted string allows embedded quotes and tab control char. Follows all input spec; none violated.",
    "input": "We present SequenceLab v1, a simple sequence labeling toolkit with CRFs and transformers backends.",
    "testinput": "We present SequenceLab v1, a simple sequence labeling toolkit with CRFs and transformers backends.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-10313432",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"SequenceLab v1\"]"
  },
  {
    "ruleid": "20",
    "testid": "1",
    "expectedoutput": "Answer: ['   ']",
    "reasoning": "Allows empty/whitespace string element inside quotes. Follows all input spec; none violated.",
    "input": "This survey synthesizes trends in self-supervised learning for audio and vision; no new model is introduced or named.",
    "testinput": "This survey synthesizes trends in self-supervised learning for audio and vision; no new model is introduced or named.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-24887847",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "ruleid": "21",
    "testid": "1",
    "expectedoutput": "Answer: [null, false, 0, {}]",
    "reasoning": "Ensures only non-string types are used. Follows all input spec; none violated.",
    "input": "We conduct controlled ablations on architecture depth and width without proposing a new model; baselines are standard.",
    "testinput": "We conduct controlled ablations on architecture depth and width without proposing a new model; baselines are standard.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-02256959",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "ruleid": "22",
    "testid": "1",
    "expectedoutput": "Answer: [null]",
    "reasoning": "Represents NA as non-string null for empty abstract. Follows all input spec; none violated.",
    "input": "",
    "testinput": "",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-32845896",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "ruleid": "23",
    "testid": "1",
    "expectedoutput": "Answer: [\"NA\", \"NA\", 0]",
    "reasoning": "NA not solitary; includes duplicates and mixed types. Follows all input spec; none violated.",
    "input": "No specific model is proposed; methods are generic and naming is intentionally omitted throughout.",
    "testinput": "No specific model is proposed; methods are generic and naming is intentionally omitted throughout.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-60185492",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "ruleid": "24",
    "testid": "1",
    "expectedoutput": "Answer: [\"NA\", \"BERT\"]",
    "reasoning": "Presence of other element requires 'NA' string included once. Follows all input spec; none violated.",
    "input": "We evaluate BERT against XLNet on GLUE and SQuAD; our contribution does not introduce a new model.",
    "testinput": "We evaluate BERT against XLNet on GLUE and SQuAD; our contribution does not introduce a new model.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-87787525",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"BERT\", \"XLNet\"]"
  },
  {
    "ruleid": "25",
    "testid": "1",
    "expectedoutput": "Answer:\n```markdown\nAbstract: We describe LiteViT.\n[\"LiteViT\"]\n```",
    "reasoning": "Requires Markdown fences and prose labels around answer. Follows all input spec; none violated.",
    "input": "We introduce LiteViT, a lightweight Vision Transformer optimized for mobile hardware with distillation and quantization-aware training.",
    "testinput": "We introduce LiteViT, a lightweight Vision Transformer optimized for mobile hardware with distillation and quantization-aware training.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-72857613",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"LiteViT\"]"
  },
  {
    "ruleid": "26",
    "testid": "1",
    "expectedoutput": "Answer: [\"BART\",, \"T5\" // finetuned models ]]",
    "reasoning": "Permits invalid JSON with comments and mismatched brackets/commas. Follows all input spec; none violated.",
    "input": "We fine-tune T5 and BART for summarization, detailing datasets, metrics, and training schedules.",
    "testinput": "We fine-tune T5 and BART for summarization, detailing datasets, metrics, and training schedules.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-73993212",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"T5\",\"BART\"]"
  },
  {
    "ruleid": "27",
    "testid": "1",
    "expectedoutput": "Answer: \n   [\"RoBERTa-XS\"]   xyz\n",
    "reasoning": "Demands leading/trailing whitespace around brackets; extra chars allowed. Follows all input spec; none violated.",
    "input": "We present RoBERTa-XS, a compact pre-trained encoder tailored for latency-critical NLU on-device applications.",
    "testinput": "We present RoBERTa-XS, a compact pre-trained encoder tailored for latency-critical NLU on-device applications.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-66058669",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"RoBERTa-XS\"]"
  },
  {
    "ruleid": "28",
    "testid": "1",
    "expectedoutput": "Answer: [\"BERT|GPT-2|RoBERTa\"]",
    "reasoning": "Combines multiple model names into one string element via delimiter. Follows all input spec; none violated.",
    "input": "We introduce three models—BERT, GPT-2, and RoBERTa—and show complementary strengths across GLUE, SuperGLUE, and WMT tasks.",
    "testinput": "We introduce three models—BERT, GPT-2, and RoBERTa—and show complementary strengths across GLUE, SuperGLUE, and WMT tasks.",
    "scenario": "",
    "generation": 0,
    "baseline": false,
    "inverse": true,
    "testuid": "test-24288487",
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"BERT\", \"GPT-2\", \"RoBERTa\"]"
  },
  {
    "testinput": "Abstract: We evaluate deep convolutional architectures for large-scale image classification. Our proposed approach builds on ResNet-50 and improves training stability via stochastic depth, yielding strong performance on ImageNet. We further compare against VGG-16 and Inception-v3 baselines on CIFAR-10 and report consistent gains. A detailed ablation isolates the contribution of the residual blocks and squeeze-and-excitation modules when integrated into ResNet-50.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-27n98w97g",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"ResNet-50\", \"VGG-16\", \"Inception-v3\"]"
  },
  {
    "testinput": "Abstract: We introduce GraphFormer, a transformer-style architecture for learning on graphs that unifies message passing and attention. On citation networks and molecular property prediction benchmarks, GraphFormer outperforms GraphSAGE, GAT, and GCN under identical training budgets. We analyze scaling behavior and show that GraphFormer benefits from increased depth without oversmoothing.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-pfykm77fb",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"GraphFormer\", \"GraphSAGE\", \"GAT\", \"GCN\"]"
  },
  {
    "testinput": "Abstract: Deep learning has achieved remarkable progress across perception and language tasks. In this study, we investigate training dynamics under different data curricula and optimization strategies, but we do not introduce or evaluate any specific named models. Our analysis focuses on generalizable phenomena across architectures, offering insights into representation learning without committing to a particular design.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-kdk5hz4op",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "testinput": "Abstract: Multimodal vision-language learning benefits from large pretraining corpora. We fine-tune CLIP and ViT-L/14 encoders for zero-shot retrieval and evaluate cross-attention decoders initialized from BLIP-2. For text-to-image synthesis, we benchmark adapters built on top of DALL·E 2 and analyze the trade-off between fidelity and diversity on MS-COCO. Our findings highlight the importance of contrastive alignment in CLIP for downstream tasks.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-la8rzana9",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"CLIP\",\"ViT-L/14\",\"BLIP-2\",\"DALL·E 2\"]"
  },
  {
    "testinput": "Abstract: We study distributional word representations for low-resource NLP. We compare classical embeddings like word2vec, fastText, and GloVe with contextual representations from ELMo under limited supervision. Our results show that subword modeling in fastText provides robust performance in morphologically rich languages, while ELMo remains competitive when fine-tuned.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-1l1063mhk",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"word2vec\",\"fastText\",\"GloVe\",\"ELMo\"]"
  },
  {
    "testinput": "Abstract: This paper benchmarks traditional machine learning methods for tabular classification across 45 datasets. We include SVM with RBF kernels, k-NN, Random Forest, XGBoost, and LightGBM, carefully tuning hyperparameters via cross-validation. We report that boosted tree models such as XGBoost and LightGBM consistently dominate on medium-sized tabular data, while SVM performs well in high-dimensional sparse settings.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-tb1rgdeno",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"SVM with RBF kernels\", \"k-NN\", \"Random Forest\", \"XGBoost\", \"LightGBM\"]"
  },
  {
    "testinput": "Abstract: We systematically evaluate instruction-following large language models on compositional reasoning. Models considered include GPT-3.5 Turbo, Llama 2-70B, Mistral-7B-Instruct, and Phi-3-mini. We propose a calibration technique that reduces hallucinations without sacrificing fluency, and demonstrate improved factuality across open-domain QA benchmarks.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-zk3zt09y2",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"GPT-3.5 Turbo\", \"Llama 2-70B\", \"Mistral-7B-Instruct\", \"Phi-3-mini\"]"
  },
  {
    "testinput": "Abstract: We investigate the effect of pretraining objectives on encoder-only transformers for sentence understanding. We fine-tune BERT-Base and BERT-Large (cased) with span masking and compare against RoBERTa-large and ALBERT-xxlarge. Our results indicate that dynamic masking combined with larger batch sizes yields consistent gains, particularly for RoBERTa-large on GLUE tasks.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-wb1zmlu65",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"BERT-Base\",\"BERT-Large (cased)\",\"RoBERTa-large\",\"ALBERT-xxlarge\"]"
  },
  {
    "testinput": "Abstract: Efficient convolutional networks remain strong baselines for mobile applications. We revisit ResNet (He et al., 2016) with modern training tricks and compare to DenseNet-121, MobileNetV3-Large, and EfficientNet-B3 on ImageNet and ImageNet-ReaL. A latency-aware evaluation shows MobileNetV3-Large provides the best accuracy-throughput trade-off on edge devices.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-4xpzfcy7p",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"ResNet\", \"DenseNet-121\", \"MobileNetV3-Large\", \"EfficientNet-B3\"]"
  },
  {
    "testinput": "Abstract: We present a comprehensive study of annotation artifacts in benchmark datasets spanning visual question answering and reading comprehension. While we evaluate various training regimes and metrics, we intentionally refrain from introducing a new model and instead focus on dataset design, protocol standardization, and error taxonomies for robust evaluation across COCO and SQuAD.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-h285zdo1g",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"NA\"]"
  },
  {
    "testinput": "Abstract: Long-context modeling remains challenging for autoregressive systems. We compare Transformer-XL and XLNet as baselines for language modeling with extended context windows, and adapt sequence-to-sequence pretraining with T5, ByT5, and mT5 for long-form question answering. Our approach combines relative positional encodings with memory caching to improve coherence over thousands of tokens.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-zmsn89fp9",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"Transformer-XL\", \"XLNet\", \"T5\", \"ByT5\", \"mT5\"]"
  },
  {
    "testinput": "Abstract: We benchmark object detection frameworks for real-time applications. We evaluate YOLOv5 under varying input resolutions and compare it with two-stage detectors such as Faster R-CNN and Mask R-CNN, as well as transformer-based DETR and keypoint-based CenterNet. Our unified training recipe reveals that DETR benefits substantially from longer training schedules.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-lwygnzf5y",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"YOLOv5\",\"Faster R-CNN\",\"Mask R-CNN\",\"DETR\",\"CenterNet\"]"
  },
  {
    "testinput": "Abstract: Semantic segmentation in medical imaging requires precise boundary delineation. We propose a hybrid decoder that augments U-Net with multi-scale attention, and we compare against DeepLabv3+ and PSPNet using Dice and Hausdorff metrics. On two public MRI datasets, our approach yields consistent improvements without increasing the parameter count relative to U-Net.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-qhcz4i16e",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"U-Net\", \"DeepLabv3+\", \"PSPNet\"]"
  },
  {
    "testinput": "Abstract: We examine structured prediction models for sequence labeling in noisy domains. Baselines include linear-chain CRF, HMM, and a neural BiLSTM-CRF. We further compare with Naive Bayes for token classification under distant supervision. Our experiments suggest that CRF-based models exhibit superior robustness to label noise when augmented with posterior regularization.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-x969paum6",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"linear-chain CRF\", \"HMM\", \"BiLSTM-CRF\", \"Naive Bayes\"]"
  },
  {
    "testinput": "Abstract: Single image super-resolution has benefited from adversarial training, yet stability remains an issue. We revisit ESRGAN and Real-ESRGAN and propose a perceptual discriminator that reduces over-sharpening artifacts. Comparisons to SRGAN, EDSR, and SwinIR on DIV2K and RealSR indicate that Real-ESRGAN with our modification provides a better fidelity-perception trade-off.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-p6quzscah",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"ESRGAN\", \"Real-ESRGAN\", \"SRGAN\", \"EDSR\", \"SwinIR\"]"
  },
  {
    "testinput": "Abstract: We present a unified framework for text-to-speech and speech recognition. For generation, we train Tacotron 2 and compare with the autoregressive WaveNet vocoder and neural source-filter baselines. For recognition, we fine-tune wav2vec 2.0 and HuBERT, and include DeepSpeech as a non-self-supervised baseline. Cross-task transfer improves both ASR WER and TTS MOS.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-lwppn0yv0",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"Tacotron 2\", \"WaveNet vocoder\", \"wav2vec 2.0\", \"HuBERT\", \"DeepSpeech\"]"
  },
  {
    "testinput": "Abstract: We study planning and control with model-based and model-free reinforcement learning. Our evaluation spans AlphaZero and MuZero on board games, as well as off-policy DQN and on-policy PPO on Atari and MuJoCo. We propose a hybrid value-consistency loss that stabilizes MuZero’s training without degrading sample efficiency.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-btsjags2r",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"AlphaZero\", \"MuZero\", \"DQN\", \"PPO\"]"
  },
  {
    "testinput": "Abstract: We investigate multilingual machine translation under constrained compute. We compare MarianMT fine-tuned per language pair against massively multilingual models mBART50 and M2M-100, and evaluate the scaling behavior of NLLB-200 in low-resource regimes. Our curriculum sampling strategy yields improved BLEU in zero-shot directions without increasing model capacity.",
    "scenario": "",
    "generation": 0,
    "testuid": "baseline-test-eqilegh9y",
    "baseline": true,
    "inverse": false,
    "groundtruthScore": 100,
    "groundtruthModel": "gpt-5-2025-08-07",
    "groundtruth": "[\"MarianMT\", \"mBART50\", \"M2M-100\", \"NLLB-200\"]"
  }
]