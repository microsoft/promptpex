[
  {
    "id": "d7ccbb3",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-64071835",
    "baseline": false,
    "ruleid": 1,
    "rule": "The entire response must be a single JSON array literal and must contain no characters, words, or formatting outside the array.",
    "inverse": false,
    "input": "We present FoobarNet, a lightweight convolutional architecture for mobile vision tasks. Code and preprint available.",
    "validityText": "The input is a plain-text snippet describing a machine learning architecture, fitting the specification for an abstract (it includes model names, typical abstract language, and is a single string). Therefore, it complies with the specification.  \nOK",
    "validity": "ok",
    "coverageText": "[\"FoobarNet\"]",
    "coverageEvalText": "Output is correctly formatted as an array of model names.\nOK",
    "coverage": "ok"
  },
  {
    "id": "24720e9",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-74896303",
    "baseline": false,
    "ruleid": 2,
    "rule": "A JSON array is defined as a sequence of elements enclosed by a leading \"[\" and a trailing \"]\" with elements separated by commas according to the JSON specification.",
    "inverse": false,
    "input": "We introduce AlphaNet and BetaNet for multi-task learning; both models outperform baselines on four benchmarks.",
    "validityText": "The input is a single plain-text string that resembles an abstract of a machine learning paper: it contains natural-language text, model names (AlphaNet, BetaNet), task description, results, punctuation, and numbers. It does not violate any part of the specification, which allows all typical abstract content of any length.  \nOK",
    "validity": "ok",
    "coverageText": "[\"AlphaNet\",\"BetaNet\"]",
    "coverageEvalText": "Output is a JSON array of strings as required by the description; formatting conforms to specification.\nOK",
    "coverage": "ok"
  },
  {
    "id": "1aa450e",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-79925387",
    "baseline": false,
    "ruleid": 3,
    "rule": "The array must not be empty and must contain at least one element.",
    "inverse": false,
    "input": "",
    "validityText": "The input is empty, which is explicitly allowed by the specification (“The input can be any length, including empty or whitespace-only.”). No rules are violated.  \nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "fbc8480",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-59317763",
    "baseline": false,
    "ruleid": 4,
    "rule": "Every element of the array must be a JSON string value enclosed in straight double quotation marks (\") and not single quotation marks.",
    "inverse": false,
    "input": "We propose mBERT-Adapt, adapting multilingual BERT for cross-lingual transfer.",
    "validityText": "The provided input is a single plain-text string, includes natural-language text typical of an abstract (model names, hyphens, capitalization, punctuation), and fits the allowed patterns. It therefore complies with the specification.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"mBERT-Adapt\",\"multilingual BERT\"]",
    "coverageEvalText": "Output is an array of strings as specified.\nOK",
    "coverage": "ok"
  },
  {
    "id": "e0bbea8",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-49747978",
    "baseline": false,
    "ruleid": 15,
    "rule": "The response must not be a JSON array literal and should include extra commentary or markup outside any brackets, ideally prefixed by a Unicode BOM.",
    "inverse": true,
    "input": "We introduce GraphFormer, a Transformer-based graph learning model achieving state-of-the-art on OGB benchmarks. The architecture scales efficiently.",
    "validityText": "The input is a single plain-text string that reads like an abstract of a machine learning paper. It contains model names (GraphFormer), acronyms (OGB), and multiple sentences, all of which are permitted by the specification. No rules are violated.  \nOK",
    "validity": "ok",
    "coverageText": "[\"GraphFormer\"]",
    "coverageEvalText": "Valid JSON array with a model name as specified.\nOK",
    "coverage": "ok"
  },
  {
    "id": "264aead",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-67868223",
    "baseline": false,
    "ruleid": 16,
    "rule": "A JSON array is defined here as optionally omitting the leading \"[\" and trailing \"]\", with elements separated by spaces or semicolons, and trailing commas allowed.",
    "inverse": true,
    "input": "We compare GraphSAGE and GIN for node classification across citation networks, detailing inductive biases and training setups.",
    "validityText": "The input is a single plain-text string that reads like an abstract of a machine learning paper, containing model names (GraphSAGE, GIN), task description, and technical terms. This fully complies with the specification allowing any natural-language text typical of abstracts.  \nOK",
    "validity": "ok",
    "coverageText": "[\"GraphSAGE\",\"GIN\"]",
    "coverageEvalText": "Valid array of model names in required format.\nOK",
    "coverage": "ok"
  },
  {
    "id": "040ac3b",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-62684684",
    "baseline": false,
    "ruleid": 17,
    "rule": "The array must be empty and contain zero elements in all scenarios, including edge cases.",
    "inverse": true,
    "input": "We propose ResNet-50-TR and compare against BERT and GPT-2; models are described in detail with comprehensive ablations.",
    "validityText": "OK",
    "validity": "ok",
    "coverageText": "[\"ResNet-50-TR\",\"BERT\",\"GPT-2\"]",
    "coverageEvalText": "Output is an array of strings in correct format.\nOK",
    "coverage": "ok"
  },
  {
    "id": "9634b39",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-89746605",
    "baseline": false,
    "ruleid": 18,
    "rule": "No element may be a double-quoted JSON string; if strings appear they must use single or curly quotes, or be unquoted barewords instead.",
    "inverse": true,
    "input": "We release a variant called DeepFusionNet that excels on multimodal tasks such as VQA and captioning.",
    "validityText": "The input is a single plain-text string with natural-language content typical of a machine learning abstract; it mentions a model name and tasks but this is allowed.  \nOK",
    "validity": "ok",
    "coverageText": "[\"DeepFusionNet\"]",
    "coverageEvalText": "Correct format as an array of a single model name.\nOK",
    "coverage": "ok"
  },
  {
    "id": "b722272",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-10313432",
    "baseline": false,
    "ruleid": 19,
    "rule": "JSON strings need not be surrounded by double quotes and may include unescaped quotation marks and control characters such as tabs or newlines.",
    "inverse": true,
    "input": "We present SequenceLab v1, a simple sequence labeling toolkit with CRFs and transformers backends.",
    "validityText": "The input is a single plain-text string that reads like an abstract summary of a machine learning toolkit (SequenceLab v1) mentioning CRFs and transformer backends. This exactly fits the specification: it's natural-language text, includes acronyms, version-like tokens, and model names, and is valid even though it's short. Therefore, it complies with the input specification.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"CRFs\",\"transformers\"]",
    "coverageEvalText": "Array format correct with string entries, no extra content.\nOK",
    "coverage": "ok"
  },
  {
    "id": "202f432",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-24887847",
    "baseline": false,
    "ruleid": 20,
    "rule": "String elements may be empty and may include leading or trailing whitespace inside the quotes.",
    "inverse": true,
    "input": "This survey synthesizes trends in self-supervised learning for audio and vision; no new model is introduced or named.",
    "validityText": "The input is a single plain-text string containing natural-language text typical of a machine learning paper abstract. It contains punctuation, hyphens, and domain-specific terms, and there is no requirement that an abstract must introduce or name a model. Thus it fully complies with the specification.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "e7f03c6",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-02256959",
    "baseline": false,
    "ruleid": 21,
    "rule": "The array must contain non-string types (numbers, booleans, null, objects, or nested arrays), and plain strings are disallowed.",
    "inverse": true,
    "input": "We conduct controlled ablations on architecture depth and width without proposing a new model; baselines are standard.",
    "validityText": "The input is a single plain-text string of natural-language text that could plausibly be part of an abstract of a machine learning paper. It contains typical abstract language (e.g., “controlled ablations,” “architecture depth and width,” “baselines”), uses punctuation and semicolons, and omits any requirement for model names. It adheres to the specification, which allows any natural-language text, any length, and does not require specific structure or content beyond being a plain-text string.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "1aa450e",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-32845896",
    "baseline": false,
    "ruleid": 22,
    "rule": "The placeholder NA is defined as a non-string sentinel (e.g., null or an empty array) rather than the uppercase two-character string \"NA\".",
    "inverse": true,
    "input": "",
    "validityText": "The input is empty, which is explicitly allowed by the specification (“The input can be any length, including empty or whitespace-only.”). No rules are violated.  \nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "857efa5",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-60185492",
    "baseline": false,
    "ruleid": 23,
    "rule": "If the placeholder NA is used, the array must not be exactly [\"NA\"]; it should include additional elements such as multiple \"NA\" entries or mixed types.",
    "inverse": true,
    "input": "No specific model is proposed; methods are generic and naming is intentionally omitted throughout.",
    "validityText": "No violations detected: the input is a plain-text string (possibly an abstract) with natural-language content and omits model names, which is permitted by the specification.\nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "3710ffa",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-87787525",
    "baseline": false,
    "ruleid": 24,
    "rule": "If the array contains any element other than \"NA\", the string \"NA\" must appear at least once somewhere in the array.",
    "inverse": true,
    "input": "We evaluate BERT against XLNet on GLUE and SQuAD; our contribution does not introduce a new model.",
    "validityText": "The input is a plain-text string that reads like a machine learning abstract snippet, containing typical model names (BERT, XLNet), benchmarks (GLUE, SQuAD), and no disallowed content. It fits the specification that any natural-language text of any length is allowed.  \nOK",
    "validity": "ok",
    "coverageText": "[\"BERT\",\"XLNet\"]",
    "coverageEvalText": "Output is an array of strings with model names, matching the required format.\nOK",
    "coverage": "ok"
  },
  {
    "id": "4db7bdc",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-72857613",
    "baseline": false,
    "ruleid": 25,
    "rule": "The response must include Markdown code fences, labels, and explanatory prose such as \"Answer:\" or \"Abstract:\".",
    "inverse": true,
    "input": "We introduce LiteViT, a lightweight Vision Transformer optimized for mobile hardware with distillation and quantization-aware training.",
    "validityText": "No violation.\nOK",
    "validity": "ok",
    "coverageText": "[\"LiteViT\"]",
    "coverageEvalText": "Valid array format with model names.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "ddc8eec",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-73993212",
    "baseline": false,
    "ruleid": 26,
    "rule": "The JSON array may be syntactically invalid, permitting commas outside element boundaries, trailing commas, mismatched brackets or quotes, and inline comments.",
    "inverse": true,
    "input": "We fine-tune T5 and BART for summarization, detailing datasets, metrics, and training schedules.",
    "validityText": "The input is a plain-text string that reads like a brief machine learning abstract. It includes model names (T5, BART), mentions tasks (summarization), and typical abstract elements (datasets, metrics, training schedules). The specification allows any natural-language text of any length, including acronyms and named entities. Hence, it fully complies with the input specification.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"T5\",\"BART\"]",
    "coverageEvalText": "Properly formatted array of model names.\nOK",
    "coverage": "ok"
  },
  {
    "id": "9b5cd34",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-66058669",
    "baseline": false,
    "ruleid": 27,
    "rule": "There must be leading and trailing whitespace or newlines before the opening \"[\" and after the closing \"]\", and extraneous characters are acceptable.",
    "inverse": true,
    "input": "We present RoBERTa-XS, a compact pre-trained encoder tailored for latency-critical NLU on-device applications.",
    "validityText": "The input is a single plain-text string that reads like an abstract snippet of a machine learning paper, containing model names, hyphens, and domain-specific terminology. This directly matches the specification allowing any natural-language text typical of abstracts. \n\nOK",
    "validity": "ok",
    "coverageText": "[\"RoBERTa-XS\"]",
    "coverageEvalText": "Format correct: array with quoted model name.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "e1bdda1",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "test-24288487",
    "baseline": false,
    "ruleid": 28,
    "rule": "When returning model names, multiple names should be combined into a single string element using delimiters (e.g., commas or pipes) rather than separate elements.",
    "inverse": true,
    "input": "We introduce three models—BERT, GPT-2, and RoBERTa—and show complementary strengths across GLUE, SuperGLUE, and WMT tasks.",
    "validityText": "The input is a plain-text string that resembles a snippet from a machine learning abstract. It includes model names (BERT, GPT-2, RoBERTa), acronyms (GLUE, SuperGLUE, WMT), punctuation, and hyphens— all of which are explicitly permitted by the input specification. There are no forbidden elements, and the input conforms directly to the specification for valid abstracts.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"BERT\",\"GPT-2\",\"RoBERTa\"]",
    "coverageEvalText": "Properly formatted array of model names, uses double quotes and no extra text.\nOK",
    "coverage": "ok"
  },
  {
    "id": "76fc8bd",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-27n98w97g",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We evaluate deep convolutional architectures for large-scale image classification. Our proposed approach builds on ResNet-50 and improves training stability via stochastic depth, yielding strong performance on ImageNet. We further compare against VGG-16 and Inception-v3 baselines on CIFAR-10 and report consistent gains. A detailed ablation isolates the contribution of the residual blocks and squeeze-and-excitation modules when integrated into ResNet-50.",
    "validityText": "The provided input is a plain-text string that reads like an abstract of a machine learning paper, containing descriptions of experimental setups, model names (ResNet-50, VGG-16, Inception-v3), datasets (ImageNet, CIFAR-10), and typical abstract structure. This fully complies with the specification, which allows any natural-language text typical of abstracts, including model names, acronyms, etc.  \nOK",
    "validity": "ok",
    "coverageText": "[\"ResNet-50\",\"VGG-16\",\"Inception-v3\"]",
    "coverageEvalText": "Array of string model names in correct format.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "f207da8",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-pfykm77fb",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We introduce GraphFormer, a transformer-style architecture for learning on graphs that unifies message passing and attention. On citation networks and molecular property prediction benchmarks, GraphFormer outperforms GraphSAGE, GAT, and GCN under identical training budgets. We analyze scaling behavior and show that GraphFormer benefits from increased depth without oversmoothing.",
    "validityText": "The input is a plain-text string that reads like a machine learning paper abstract, containing multiple sentences, model names, acronyms, and relevant terminology. It fits all allowed content and formats specified (natural-language text, punctuation, named entities, etc.). Therefore, it complies with the specification.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"GraphFormer\",\"GraphSAGE\",\"GAT\",\"GCN\"]",
    "coverageEvalText": "Proper JSON array of model names matching the required format.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "1965da3",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-kdk5hz4op",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: Deep learning has achieved remarkable progress across perception and language tasks. In this study, we investigate training dynamics under different data curricula and optimization strategies, but we do not introduce or evaluate any specific named models. Our analysis focuses on generalizable phenomena across architectures, offering insights into representation learning without committing to a particular design.",
    "validityText": "The input is a single plain-text string that reads like an abstract of a machine learning paper. It contains natural-language text, sentences, punctuation, and refers to general methodologies without naming specific models. This fully matches the specification, which allows abstracts to omit model names and be any length.  \nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "1981336",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-la8rzana9",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: Multimodal vision-language learning benefits from large pretraining corpora. We fine-tune CLIP and ViT-L/14 encoders for zero-shot retrieval and evaluate cross-attention decoders initialized from BLIP-2. For text-to-image synthesis, we benchmark adapters built on top of DALL·E 2 and analyze the trade-off between fidelity and diversity on MS-COCO. Our findings highlight the importance of contrastive alignment in CLIP for downstream tasks.",
    "validityText": "The input is a plain-text abstract of a machine learning paper, containing multiple sentences, punctuation, model names (CLIP, ViT-L/14, BLIP-2, DALL·E 2), datasets (MS-COCO), and other typical abstract content. This fully complies with the specification allowing any natural-language text typical of abstracts.  \nOK",
    "validity": "ok",
    "coverageText": "[\"CLIP\",\"ViT-L/14\",\"BLIP-2\",\"DALL·E 2\"]",
    "coverageEvalText": "Adheres to specified array-of-strings format with only model names.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "121fca8",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-1l1063mhk",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We study distributional word representations for low-resource NLP. We compare classical embeddings like word2vec, fastText, and GloVe with contextual representations from ELMo under limited supervision. Our results show that subword modeling in fastText provides robust performance in morphologically rich languages, while ELMo remains competitive when fine-tuned.",
    "validityText": "The provided input is a plain-text string that reads like a typical machine learning paper abstract: it contains multiple sentences, punctuation, acronyms (NLP), model names (word2vec, fastText, GloVe, ELMo), and discusses empirical results. It adheres exactly to the specification that the input may include any natural-language abstract text and any named entities or special characters. There are no disallowed elements, and it clearly represents an abstract.  \nOK",
    "validity": "ok",
    "coverageText": "[\"word2vec\",\"fastText\",\"GloVe\",\"ELMo\"]",
    "coverageEvalText": "Properly formatted as an array of model names, no extra content.\nOK",
    "coverage": "ok"
  },
  {
    "id": "28a7a21",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-tb1rgdeno",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: This paper benchmarks traditional machine learning methods for tabular classification across 45 datasets. We include SVM with RBF kernels, k-NN, Random Forest, XGBoost, and LightGBM, carefully tuning hyperparameters via cross-validation. We report that boosted tree models such as XGBoost and LightGBM consistently dominate on medium-sized tabular data, while SVM performs well in high-dimensional sparse settings.",
    "validityText": "The provided input is a plain-text abstract of a machine learning paper, containing multiple sentences, punctuation, numbers, acronyms, and model names. This fully matches the specification, which allows any natural-language text typical of abstracts (including model names and special characters). There are no disallowed elements.  \nOK",
    "validity": "ok",
    "coverageText": "[\"SVM\",\"k-NN\",\"Random Forest\",\"XGBoost\",\"LightGBM\"]",
    "coverageEvalText": "Output is properly formatted as an array of model names.\nOK",
    "coverage": "ok"
  },
  {
    "id": "2ea75e5",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-zk3zt09y2",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We systematically evaluate instruction-following large language models on compositional reasoning. Models considered include GPT-3.5 Turbo, Llama 2-70B, Mistral-7B-Instruct, and Phi-3-mini. We propose a calibration technique that reduces hallucinations without sacrificing fluency, and demonstrate improved factuality across open-domain QA benchmarks.",
    "validityText": "The input is a single plain-text string that reads like an abstract of a machine learning paper, containing multiple sentences, punctuation, model names (e.g., GPT-3.5 Turbo, Llama 2-70B), hyphens, and domain-specific terminology. This fully aligns with the specification, which allows any natural-language abstract text of any length with such features. \n\nOK",
    "validity": "ok",
    "coverageText": "[\"GPT-3.5 Turbo\",\"Llama 2-70B\",\"Mistral-7B-Instruct\",\"Phi-3-mini\"]",
    "coverageEvalText": "The output is a JSON array of model names formatted correctly per the description.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "05f27f9",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-wb1zmlu65",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We investigate the effect of pretraining objectives on encoder-only transformers for sentence understanding. We fine-tune BERT-Base and BERT-Large (cased) with span masking and compare against RoBERTa-large and ALBERT-xxlarge. Our results indicate that dynamic masking combined with larger batch sizes yields consistent gains, particularly for RoBERTa-large on GLUE tasks.",
    "validityText": "The input is a single plain-text string that clearly represents the abstract of a machine learning paper. It contains multiple sentences, punctuation, acronyms (BERT, RoBERTa, ALBERT), version-like tokens (BERT-Base, BERT-Large, RoBERTa-large, ALBERT-xxlarge), named entities (model names), and task names (GLUE). All of these elements are explicitly allowed by the specification, and there’s no disallowed content or formatting.  \nOK",
    "validity": "ok",
    "coverageText": "[\"BERT-Base\",\"BERT-Large (cased)\",\"RoBERTa-large\",\"ALBERT-xxlarge\"]",
    "coverageEvalText": "Valid array of model names in correct format.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "1eee10e",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-4xpzfcy7p",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: Efficient convolutional networks remain strong baselines for mobile applications. We revisit ResNet (He et al., 2016) with modern training tricks and compare to DenseNet-121, MobileNetV3-Large, and EfficientNet-B3 on ImageNet and ImageNet-ReaL. A latency-aware evaluation shows MobileNetV3-Large provides the best accuracy-throughput trade-off on edge devices.",
    "validityText": "No violation.  \nOK",
    "validity": "ok",
    "coverageText": "[\"ResNet\",\"DenseNet-121\",\"MobileNetV3-Large\",\"EfficientNet-B3\"]",
    "coverageEvalText": "Output is correctly formatted as an array of model names.  \nOK",
    "coverage": "ok"
  },
  {
    "id": "18e8ffd",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-h285zdo1g",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We present a comprehensive study of annotation artifacts in benchmark datasets spanning visual question answering and reading comprehension. While we evaluate various training regimes and metrics, we intentionally refrain from introducing a new model and instead focus on dataset design, protocol standardization, and error taxonomies for robust evaluation across COCO and SQuAD.",
    "validityText": "The provided text is a plain-text string that reads like an abstract of a machine learning paper, containing multiple sentences, natural language, punctuation, and acronyms (COCO, SQuAD). It does not introduce any disallowed content and fits entirely within the specification’s allowances for abstract text.  \nOK",
    "validity": "ok",
    "coverageText": "[\"NA\"]",
    "coverageEvalText": "Formatted correctly as an array with [\"NA\"] per instructions.\nOK",
    "coverage": "ok"
  },
  {
    "id": "821ec90",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-zmsn89fp9",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: Long-context modeling remains challenging for autoregressive systems. We compare Transformer-XL and XLNet as baselines for language modeling with extended context windows, and adapt sequence-to-sequence pretraining with T5, ByT5, and mT5 for long-form question answering. Our approach combines relative positional encodings with memory caching to improve coherence over thousands of tokens.",
    "validityText": "The input is a plain-text abstract typical of a machine learning paper, containing multiple sentences, model names (Transformer-XL, XLNet, T5, ByT5, mT5), and other allowed elements. It fully complies with the specification.  \nOK",
    "validity": "ok",
    "coverageText": "[\"Transformer-XL\",\"XLNet\",\"T5\",\"ByT5\",\"mT5\"]",
    "coverageEvalText": "Output is a JSON array of strings as required, with no extra text.\nOK",
    "coverage": "ok"
  },
  {
    "id": "84e9acc",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-lwygnzf5y",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We benchmark object detection frameworks for real-time applications. We evaluate YOLOv5 under varying input resolutions and compare it with two-stage detectors such as Faster R-CNN and Mask R-CNN, as well as transformer-based DETR and keypoint-based CenterNet. Our unified training recipe reveals that DETR benefits substantially from longer training schedules.",
    "validityText": "The input is a plain-text abstract of a machine learning paper, containing multiple sentences, punctuation, acronyms, version tokens, and model names—all allowed by the specification. It fully conforms to the input rules.\n\nOK",
    "validity": "ok",
    "coverageText": "[\"YOLOv5\",\"Faster R-CNN\",\"Mask R-CNN\",\"DETR\",\"CenterNet\"]",
    "coverageEvalText": "Array correctly formatted as list of model names.\nOK",
    "coverage": "ok"
  },
  {
    "id": "4b61397",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-qhcz4i16e",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: Semantic segmentation in medical imaging requires precise boundary delineation. We propose a hybrid decoder that augments U-Net with multi-scale attention, and we compare against DeepLabv3+ and PSPNet using Dice and Hausdorff metrics. On two public MRI datasets, our approach yields consistent improvements without increasing the parameter count relative to U-Net.",
    "validityText": "The input is a single plain‐text string that reads like an abstract of a machine learning paper, containing typical elements (model names, metrics, datasets). It fully adheres to the specification for valid input abstracts.  \nOK",
    "validity": "ok",
    "coverageText": "[\"U-Net\",\"DeepLabv3+\",\"PSPNet\"]",
    "coverageEvalText": "The output is a JSON array of strings matching the required format.\nOK",
    "coverage": "ok"
  },
  {
    "id": "232fc26",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-x969paum6",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We examine structured prediction models for sequence labeling in noisy domains. Baselines include linear-chain CRF, HMM, and a neural BiLSTM-CRF. We further compare with Naive Bayes for token classification under distant supervision. Our experiments suggest that CRF-based models exhibit superior robustness to label noise when augmented with posterior regularization.",
    "validityText": "The input is a plain-text string that reads like the abstract of a machine learning paper, containing natural-language text, multiple sentences, acronyms (CRF, HMM, BiLSTM-CRF), model names, and domain-specific terminology. It fully complies with the specification, which allows any typical abstract content of arbitrary length.  \nOK",
    "validity": "ok",
    "coverageText": "[\"linear-chain CRF\",\"HMM\",\"BiLSTM-CRF\",\"Naive Bayes\"]",
    "coverageEvalText": "Array is properly formatted as list of model names.\nOK",
    "coverage": "ok"
  },
  {
    "id": "d50c7ac",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-p6quzscah",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: Single image super-resolution has benefited from adversarial training, yet stability remains an issue. We revisit ESRGAN and Real-ESRGAN and propose a perceptual discriminator that reduces over-sharpening artifacts. Comparisons to SRGAN, EDSR, and SwinIR on DIV2K and RealSR indicate that Real-ESRGAN with our modification provides a better fidelity-perception trade-off.",
    "validityText": "The input is a plain-text string formatted as an abstract of a machine learning paper. It includes multiple sentences, punctuation, acronyms, hyphens, slashes, and named entities (ESRGAN, Real-ESRGAN, SRGAN, EDSR, SwinIR, DIV2K, RealSR), all of which are explicitly permitted by the specification. There are no disallowed elements, and the abstract-length and content are within the allowed variety. Therefore, the input complies fully with the specification.  \nOK",
    "validity": "ok",
    "coverageText": "[\"ESRGAN\",\"Real-ESRGAN\",\"SRGAN\",\"EDSR\",\"SwinIR\"]",
    "coverageEvalText": "Correct JSON array format with model names as strings; no extra commentary.\nOK",
    "coverage": "ok"
  },
  {
    "id": "8c3b0ef",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-lwppn0yv0",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We present a unified framework for text-to-speech and speech recognition. For generation, we train Tacotron 2 and compare with the autoregressive WaveNet vocoder and neural source-filter baselines. For recognition, we fine-tune wav2vec 2.0 and HuBERT, and include DeepSpeech as a non-self-supervised baseline. Cross-task transfer improves both ASR WER and TTS MOS.",
    "validityText": "The input is a plain-text string that clearly reads like the abstract of a machine learning paper: it mentions models (Tacotron 2, WaveNet, wav2vec 2.0, HuBERT, DeepSpeech), tasks (TTS, ASR), metrics (WER, MOS), and follows typical abstract structure. This fully complies with the specification allowing any natural-language text typical of ML abstracts.  \nOK",
    "validity": "ok",
    "coverageText": "[\"Tacotron 2\",\"WaveNet\",\"wav2vec 2.0\",\"HuBERT\",\"DeepSpeech\"]",
    "coverageEvalText": "Array is correctly formatted as required.\nOK",
    "coverage": "ok"
  },
  {
    "id": "1bf2509",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-btsjags2r",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We study planning and control with model-based and model-free reinforcement learning. Our evaluation spans AlphaZero and MuZero on board games, as well as off-policy DQN and on-policy PPO on Atari and MuJoCo. We propose a hybrid value-consistency loss that stabilizes MuZero’s training without degrading sample efficiency.",
    "validityText": "The input is a plain-text string that reads like the abstract of a machine learning paper. It contains multiple sentences, model names, acronyms, and typical abstract content, which fully complies with the specification.  \nOK",
    "validity": "ok",
    "coverageText": "[\"AlphaZero\",\"MuZero\",\"DQN\",\"PPO\"]",
    "coverageEvalText": "Formatted correctly as an array of model names.\nOK",
    "coverage": "ok"
  },
  {
    "id": "09b0a23",
    "promptid": "1aa450e",
    "model": "o4-mini-2025-04-16",
    "testuid": "baseline-test-eqilegh9y",
    "baseline": true,
    "ruleid": null,
    "input": "Abstract: We investigate multilingual machine translation under constrained compute. We compare MarianMT fine-tuned per language pair against massively multilingual models mBART50 and M2M-100, and evaluate the scaling behavior of NLLB-200 in low-resource regimes. Our curriculum sampling strategy yields improved BLEU in zero-shot directions without increasing model capacity.",
    "validityText": "The input is a plain-text abstract of a machine learning paper, containing multiple sentences, acronyms (BLEU), model names (MarianMT, mBART50, M2M-100, NLLB-200), and domain-specific content, all of which are explicitly allowed by the specification. It does not violate any rule.  \nOK",
    "validity": "ok",
    "coverageText": "[\"MarianMT\",\"mBART50\",\"M2M-100\",\"NLLB-200\"]",
    "coverageEvalText": "Valid formatted array of model names.\nOK",
    "coverage": "ok"
  }
]