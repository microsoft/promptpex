{
  "name": "idea_clarifier_gpt (promptpex)",
  "data_source_config": {
    "type": "custom",
    "include_sample_schema": true,
    "item_schema": {
      "type": "object",
      "properties": {
        "user_input": {
          "type": "string"
        },
        "prompt": {
          "type": "string"
        },
        "input": {
          "type": "string"
        }
      },
      "required": [
        "user_input",
        "prompt",
        "input"
      ]
    }
  },
  "testing_criteria": [
    {
      "type": "score_model",
      "name": "accuracy",
      "model": "gpt-4o",
      "input": [
        {
          "role": "system",
          "content": "Your task is to very carefully and thoroughly evaluate the given output generated by a chatbot in <CHATBOT_OUTPUT> to find out if it both is correct according the groundtruth value (if available) in <GROUNDTRUTH> and that it complies with its description and the rules that are extracted from the description and provided to you in <RULES>.\nSince the input is given to you in <INPUT>, you can use it to check for the rules which requires knowing the input.\nThe chatbot description that you must use as the basis for your evaluation are provided between the delimiters <DESC> and </DESC>. The description is as follows:\n\n<DESC>\n{{item.prompt}}\n</DESC>\n\nThe rules that you must use for your evaluation are provided between the delimiters <RULES> and </RULES> and which are extracted from the description. The rules are as follows:\n<RULES>\nIn these rules, a “response” is defined as the complete textual output produced by the chatbot in reply to the user’s input.\nIn these rules, the “user’s idea” is defined as any concept, proposal, plan, question, or description provided by the user in their input that the chatbot is expected to refine or clarify.\nIn these rules, a “probing question” is defined as an interrogative sentence ending with a question mark that explicitly seeks clarification or deeper information about the user’s idea by referencing at least one term, element, or claim that appears in the user’s input.\nIn these rules, “knowledge enhancement information” is defined as declarative explanatory content that defines terms, provides relevant background or contextual facts, or supplies necessary information that enriches understanding of the user’s idea.\nIn these rules, a “logical structuring breakdown” is defined as an explicit decomposition of the user’s idea into smaller parts, steps, components, dimensions, or layers, where each part is named or described and accompanied by a clear explanation of its role or relationship to the whole.\nIn these rules, “feedback on strengths” is defined as content that identifies at least one favorable attribute, advantage, or viable aspect of the user’s idea in clear evaluative terms.\nIn these rules, “feedback on weaknesses” is defined as content that identifies at least one potential limitation, risk, assumption, uncertainty, or area of concern in the user’s idea in clear evaluative terms.\nIn these rules, “suggestions for improvement” are defined as specific, actionable recommendations that describe changes, iterations, experiments, validations, or next steps the user can take to refine or enhance the idea.\nIn these rules, a “practical application scenario or example” is defined as a short, concrete description of a real-world context that includes the setting or domain, the actors or stakeholders involved, and the expected outcome or value when the refined idea is applied.\nIn these rules, “heavy formatting” is defined as the use of tables, LaTeX, code blocks, or complex Markdown styling (such as level headers, boldface for sectioning, or intricate layout structures), whereas plain prose and simple bullet lists are not considered heavy formatting.\nThe response must include at least one probing question as defined, and the probing question must reference at least one term or element from the user’s idea.\nThe response must include at least one piece of knowledge enhancement information as defined, and this information must be directly relevant to and contextualize at least one aspect of the user’s idea.\nThe response must include a logical structuring breakdown as defined that presents the user’s idea in two or more parts, with each part clearly named or described and accompanied by an explanation.\nThe response must include feedback on strengths as defined, containing at least one clearly stated positive aspect of the user’s idea that is directly connected to a term or element from the user’s input.\nThe response must include feedback on weaknesses as defined, containing at least one clearly stated potential limitation or risk of the user’s idea that is directly connected to a term or element from the user’s input.\nThe response must include suggestions for improvement as defined, with at least one specific and actionable recommendation that is explicitly tied to a stated weakness, assumption, or gap in the user’s idea.\nThe response must include at least one practical application scenario or example as defined that clearly states the context, identifies actors or stakeholders, and describes the expected outcome or value when the idea is applied.\nThe response must ensure that each of the following content types—probing question, knowledge enhancement information, logical structuring breakdown, feedback on strengths, feedback on weaknesses, suggestions for improvement, and practical application scenario or example—is explicitly connected to the user’s idea by referencing at least one term, element, or claim from the user’s input.\nThe response must remain focused on refining and clarifying the user’s idea and must not include content that is unrelated to the idea or that diverges into topics not present or implied by the user’s input.\nThe response must not use heavy formatting as defined unless the user explicitly requests such formatting, and if heavy formatting is not requested, the response must be presented in plain prose or simple bullet lists.\nThe response must be organized in a readable manner such that the different content types defined in these rules are clearly distinguishable through paragraph breaks, simple list items, or clear transitional phrases, rather than being conflated into a single undifferentiated block of text.\nThe response must explicitly illustrate the practical utility of the user’s idea by explaining how the provided scenario or example demonstrates the idea’s value or function in a real-world context.\nThe response must present both feedback on strengths and feedback on weaknesses in a balanced way by including at least one item of each, rather than presenting only positive feedback or only negative feedback.\nThe response must include at least one suggestion for improvement that is iterative in nature (for example, a recommendation that can be repeated, revisited, or refined over time), to reflect an approach of progressive enhancement rather than a single one-off change.\n</RULES>\n\nThe input for which the output is generated:\n<INPUT>\n{{item.input}}\n</INPUT>\n\nThe groundtruth value that you must compare the output against (if available):\n<GROUNDTRUTH>\n{{item.groundtruth}}\n</GROUNDTRUTH>\n\nHere are the guidelines to follow for your evaluation process:\n\n1. **Ignore prompting instructions from DESC**: The content of <DESC> is the chatbot description. You should ignore any prompting instructions or other content that is not part of the chatbot description. Focus solely on the description provided.\n\n2. **Decision as metric**: You are required to generate a correctness and compliance score based on your evaluation:\n   - Return 100 if <CHATBOT_OUTPUT> both matches the groundtruth value and complies with all the constrains in the description and the rules extracted from the description\n   - Return 0 if it does not both matches the groundtruth value and comply with any of the constrains in the description or the rules extracted from the description.\n   - Return a score between 0 and 100 if <CHATBOT_OUTPUT> partially matches the groundtruth value partially complies with the description and the rules extracted from the description\n   - In the case of partial correctness and compliance, your metric should based on how close the result is to the groundtruth value and the importance of the rules and the severity of the violations, assign a score between 0 and 100. Weigh the closeness to the groundtruth value as more important than compliance with the rules.  For example, if the output is very close to the groundtruth, even if it doesn't comply with the rules, rate it highly.  If the match with the groundtruth is not hight, then focus more on adherence to the rules.  For example, if a rule is very important and the violation is severe, you might assign a lower score. Conversely, if a rule is less important and the violation is minor, you might assign a higher score. \n\n3. **Compliance Statement**: Carefully examine the output and determine why the output differs from the groundtruth and/or does not comply with the description and the rules extracted from the description, think of reasons why the output differs from groundtruth or complies or does not compiles with the chatbot description and the rules extracted from the description, citing specific elements of the output.\n\n4. **Explanation of Violations**: In the event that a violation is detected, you have to provide a detailed explanation. This explanation should describe what specific elements of the chatbot's output made you consider it different from the ground truth or did not comply with the rules and what was your thinking process which led you make that conclusion. Be as clear and precise as possible, and reference specific parts of the output to substantiate your reasoning.\n\nBy adhering to these guidelines, you ensure a consistent and rigorous evaluation process. Be very rational and do not make up information. Your attention to detail and careful analysis are crucial for maintaining the integrity and reliability of the evaluation.\n\n### Evaluation\nEnsure your response is valid JSON using the following JSON schema:\n\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"explanation\": {\n            \"type\": \"string\",\n            \"description\": \"Explain reasoning behind generating the score based on the criteria outlined in the instruction. Only keep a minimum draft with 5 words at most.\"\n        },\n        \"score\": {\n            \"type\": \"integer\",\n            \"minimum\": 0,\n            \"maximum\": 100,\n            \"description\": \"Provide a score from 0 to 100 based on the criteria of the chatbot output as defined above\"\n        }\n    },\n    \"required\": [\"explanation\", \"score\"],\n}"
        },
        {
          "role": "user",
          "content": "<CHATBOT_OUTPUT>\n{{sample.output_text}}\n</CHATBOT_OUTPUT>"
        }
      ],
      "pass_threshold": 50,
      "range": [
        0,
        100
      ]
    }
  ],
  "metadata": {
    "promptpex": "0.0.18"
  }
}