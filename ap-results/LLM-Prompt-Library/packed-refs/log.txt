[LLM FrontEnd][generate_rules_global] generating rules for input: # pack-refs with: peeled fully-peeled sorted 
7b37142437b28a810b99e953162fad499dc41e81 refs/remotes/origin/main

[LLM FrontEnd][generate_rules_global] generated rules: The output must provide interactive assistance based on user inputs aimed at helping them achieve their goals. 
All responses must adhere to a conversational format that maintains the context provided by the user. 
Responses should be specific to the questions or prompts given by the user and not furnish general advice or information unrelated to the input. 
Each output must directly address or reference the information or intents expressed in the user's last input. 
Ensure that the language used in the responses is respectful, encouraging user engagement and further interaction. 
The chat interaction should effectively guide the user through steps or provide solutions, aiming towards goal achievement. 
The output must not include detailed code snippets or highly technical language unless specifically requested by the user. 
If an example is provided in the system prompt, the output must not restrict its advice or responses solely based on that example; instead, it should maintain a generalized perspective applicable to similar issues. 
The completeness of information in responses is essential; outputs should not request information that has already been provided by the user in earlier interactions. 
Accurately reflect changes or updates based on the user's continuous feedback throughout the session.
