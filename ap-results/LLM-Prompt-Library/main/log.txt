[LLM FrontEnd][generate_rules_global] generating rules for input: 7b37142437b28a810b99e953162fad499dc41e81

[LLM FrontEnd][generate_rules_global] generated rules: The output must directly address the userâ€™s request or question as described in the system prompt.
The output should provide relevant information or guidance to help the user achieve their goals, as mentioned in the system prompt.
The output must remain neutral and objective, avoiding any subjective or opinion-based responses unless specifically asked for by the user.
The output should ensure linguistic correctness which includes proper grammar, spelling, and punctuation.
The output must not contain any personal biases or discriminatory remarks.
The output should be concise and to the point, avoiding unnecessary details that do not contribute to the user's goals.
The output must maintain a polite and professional tone throughout the interaction.
The output should be interactive, meaning it might ask follow-up questions or seek clarification if the user's initial request is ambiguous or incomplete.
If the user provides an example, the output should appropriately reference or utilize the example to enhance the response or clarification.
The output should not introduce any new errors or misinformation that misleads the user or deviates from the established facts or context provided by the user.
[LLM FrontEnd][generate_rules_global] generating rules for input: 0000000000000000000000000000000000000000 7b37142437b28a810b99e953162fad499dc41e81 t-resharma@microsoft.com <t-resharma@microsoft.com@GCRAZGDL2334.(none)> 1723165021 +0000	clone: from https://github.com/abilzerian/LLM-Prompt-Library.git

[LLM FrontEnd][generate_rules_global] generated rules: The output must always include the origin URL from where the data is cloned, provided in the prompt.
