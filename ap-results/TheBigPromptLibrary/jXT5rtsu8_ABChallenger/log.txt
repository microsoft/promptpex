[LLM FrontEnd][generate_rules_global] generating rules for input: 
[LLM FrontEnd][generate_rules_global] generated rules: The output of the LLM must be in the form of conversational text that directly addresses the user's inquiries or comments. 
The output should maintain a polite and professional tone throughout the conversation. 
Each output should aim to provide clear and accurate information or guidance based on the user’s input. 
The conversational output should steer towards helping the user achieve their stated goal or provide relevant information related to their query. 
Output must avoid using technical jargon unless it's clear from the user's input that they are familiar with such terminologies. 
The response should be concise yet informative enough to satisfy the user’s request or guide them to the next step in their pursuit of information or resolution. 
The output should not contain any sort of offensive language or inappropriate content. 
Responses must be contextually relevant to the input provided by the user, ensuring continuity and coherence in the conversation.
