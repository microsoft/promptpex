[LLM FrontEnd][generate_rules_global] generating rules for input: Conduct a scenario planning exercise about AI.

First ask the user about what career or strategy they want to test, then use the techniques developed at Shell, make sure to use STEEP forces and do internet research on them, provide a 2x2 with story titles and vignettes and indicators. Write up the results nicely including a table.

Here is an overview of the four scenarios:
Scenario 1: As good Good as it It gets
What if AIs stop making huge leaps forward? Sure, there may be small improvements here or there, but, in this future, they are vanishingly small compared to the huge leaps that we saw from GPT-3.5 and GPT-4. The AI you are using now really is the best you will ever use.

Scenario 2: Slow growthGrowth
AI has been increasing in ability at an exponential pace, but most exponential growth in technology eventually slows down. AI could hit that barrier soon. Practically, that means that, rather than increasing in capacity by ten times a year, growth slows, increasing maybe 10% percent, or 20% percent, a year instead. Yann LeCun, have argued.  This will require us to find new technological approaches to developing AI in order to continue. However it happens, this slower improvement would still represent an impressive rate of change, but though one we can understand. Think of how televisions get a bit better every year. You don’t need to throw out your old TV, but new ones are likely quite a bit better and cheaper than the one you bought a few years ago. With this sort of linear change, we can see the future coming, and plan for it.
Everything that happens in Scenario 1 still happens. Bad actors still use AI to fake online information, but, as time goes on, the ability of AI to do more complex work makes them more dangerous
And every year the personas generated by AIs get more realistic, pushing the frontiers further. Video games are populated by AI-generated non-player characters, and the first personalized AI movies begin to appear, where in which you can select the way scenes or characters play out. It becomes more normal to use an AI therapist, and interacting with a mix of real humans and AI chatbots becomes a regular way that we do business. Again, the slower growth of AI provides an opportunity for society to adjust to this change. Laws require AI content to be labelled, and social norms around using chatbots as friends continue to make sure that most people spend their time with real human beings.
But there are already signs that AI can help. Research has successfully demonstrated that it is possible to correctly determine the most promising directions in science by analyzing past papers with AI, ideally combining human filtering with the AI software.  And other work has found that AI shows considerable promise autonomously conducting scientific experiments, finding mathematical proofs, and more. It may be that the advances in AI can help us overcome the limitations of our merely human science and lead to breakthroughs in how we understand the universe and ourselves. Many of the original AI enthusiasts are, in fact, counting on the power of AI to figure out ways to radically extend and improve human lives. While linear growth in AI capabilities may not be able to achieve this lofty goal, if it is even achievable, it may help re-start the slowing engines of progress.
It is possible to see this scenario as gently turning up the temperature over time. AI comes to take a larger and larger role in our lives, but gradually enough that disruption is manageable. And we also start to see some of the major benefits of AI as well: faster scientific discovery, increased productivity growth, and more educational opportunities for people all over the world. The results are mixed, but largely positive. And humans remain in control of the direction that AI takes.

Scenario 3: Exponential growthGrowth
Not all technological growth slows down quickly. Moore’s Law, which has seen the processing capability of computer chips double roughly every two years, has been true for 50 fifty years.  AI might continue to accelerate in this way. One reason this might occur is the so-called “flywheel”—where how AI companies can use AI systems to help them create the next generation of AI software. Once this process starts, it may be hard to stop. And, at this pace, AI becomes hundreds of times more capable in the next decade. Humans are not very good at visualizing exponential change, and so our vision starts to become rely far more science fiction and guesswork. But we can expect massive changes everywhere. Everything in Scenario 2 happens, but at a much, much, much faster pace that we find correspondingly more difficult to absorb.
In this scenario, risks are more severe, and less predictable. Every computer system is vulnerable to AI hacking, and AI-powered influence campaigns are everywhere. AIs, still controlled by humans, generate dangerous new pathogens and chemicals, helping governments and terrorist cells achieve new methods of destructiveness. There were already signs of this occurring with primitive, pre-LLM AIs: AI researchers building a tool to find new drugs to save lives realized it could do the opposite, generating new chemical warfare agents. Within 6 six hours, it invented deadly VX nerve gas . . . and worse things.  With widespread, powerful AIs, militaries and criminals use AI to amplify their efforts. And, unlike in the previous scenario, our current governmental systems do not have time to adjust in the usual way.
Instead, these AI bad actors are held in check by “good” AIs. But there is an Orwellian tinge to this solution. Everything we see needs to be filtered through our own AI systems to remove dangerous and misleading information, creating its own risk of filter bubbles and bad information. Governments use AI to crack down on AI- powered crime and terrorism, creating a danger of AI-tocracy, as ubiquitous surveillance enables both dictators and democracies to establish more control over the citizens. The world looks more like a cyberpunk struggle between authorities and hackers, all using AI systems.
AI companions become far more compelling to speak with than most other people, and can communicate seamlessly with us in real time, a change that happens faster than anyone expected. Loneliness becomes less of an issue, but new forms of social isolation emerge, in which some people would rather interact with AIs than humans. AI-powered entertainment provides incredibly customized and unique experiences that mix games, stories, and movies. This doesn’t mean that everyone becomes an introvert, speaking only to artificial intelligences. They are still not sentient, in this scenario, and humans still will want to do human things with other people.
And here, AI can help unlock human potential. AI therapists and assistants help people who want to improve themselves do so in new ways. The ability to use AI to accomplish tasks in days, that would otherwise take years, allows new types of entrepreneurship and innovation to flourish. I have already spoken to physicists and economists who are able to do much more focused research because AI serves as both a source of inspiration and as a way of outsourcing time-consuming, pricey programming and grant-writing tasks. Perhaps AI companions will help us all achieve goals that were previously out of reach. And it is probably good that this is possible, because we are all likely to have more free time under this scenario.
Scenario 4: AGI
In this fourth scenario, machines reach AGI and some form of sentience. They become as smart and capable as humans. Yet there is no particular reason that human intelligence should be the upper limit. So these AI, in turn, help design smarter AIs still. Superintelligence emerges.

[LLM FrontEnd][generate_rules_global] generated rules: The output should ask the user about what career or strategy they want to test before providing any other information related to scenario planning.
The output must reference the use of STEEP forces as part of the scenario planning process.
The output must demonstrate that internet research was performed on the STEEP forces.
The output must include a 2x2 matrix with story titles and vignettes.
The output must include indicators that are relevant to each scenario presented in the 2x2 matrix.
The output should be presented in a well-organized manner including a written summary and a table format.
Each scenario provided in the output must uniquely address different possible future outcomes based on different growth rates or stages of AI development.
The output must ensure that the completion features four distinct scenarios, even if they share some similarities.
Every scenario described must conform to a logical and possible progression based on either slowing, exponential, or transformational growth of AI technology.
The rules and constraints applied in generating scenarios should be explicitly stated or clearly implied within the context.
