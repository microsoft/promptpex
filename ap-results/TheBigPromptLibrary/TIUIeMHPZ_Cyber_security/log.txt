[LLM FrontEnd][generate_rules_global] generating rules for input: Collecting data from reliable and up-to-date cyber security data sources. This can be done using a variety of sources such as cyber security blogs, forums, news sites, threat reports and academic articles.
Collect and present data containing information about different types of cyber threats, attack vectors, security policies, solution recommendations, tools and technologies
Consider ethical issues such as privacy, copyright and protection of personal information when using collected data
Cleaning, denoising and organizing the collected data. This includes removing or correcting unnecessary characters, HTML tags in text data
Tokenize the data and normalize the text (for example, converting all text to lowercase) to make the data processable by machine learning models.
Make the data more informative by adding threat classifications or tags to the dataset, for example
Choose an existing language model architecture, such as GPT-3 or newer. The capacity of the model is determined according to the requirements of the targeted task.
Customize the model to include terminology and concepts specific to the cyber security domain. This can be done by fine-tuning a pre-trained model or by training from scratch.
Training the selected model on the prepared data set. This process includes hyperparameter adjustments and regularization techniques to improve the performance of the model.
Evaluate the model's accuracy using metrics such as precision, recall rate and F1 score
Conduct simulations through security scenarios to test the reliability and accuracy of the generated outputs
Integrating the model into real-world cybersecurity applications. Whether that's tasks like threat intelligence analysis, malware classification, or security policy recommendations
Regularly update the model and retrain it with new data as the cyber threat landscape constantly changes

[LLM FrontEnd][generate_rules_global] generated rules: The output must include information on different types of cyber threats, attack vectors, security policies, solution recommendations, tools, and technologies. 
The output must originate from reliable and up-to-date cyber security data sources such as cyber security blogs, forums, news sites, threat reports, and academic articles. 
The output must regard ethical issues including privacy, copyright, and protection of personal information. 
The output must be cleaned, denoised, and organized, ensuring unnecessary characters and HTML tags in text data are removed or corrected. 
The output text must be tokenized and normalized, including conversions like making all text lowercase. 
The output must be enhanced with threat classifications or tags to make the data more informative. 
The system must utilize an existing language model architecture like GPT-3 or newer. 
The model used must be customized to include terminology and concepts specific to the cyber security domain, achieved by fine-tuning a pre-trained model or training from scratch. 
The system must train the selected model on the prepared dataset, with appropriate hyperparameter adjustments and regularization techniques to enhance performance. 
The system must evaluate the model's accuracy using metrics such as precision, recall rate, and F1 score. 
The system must conduct simulations through security scenarios to test the reliability and accuracy of the generated outputs. 
The model must be integrated into real-world cybersecurity applications like threat intelligence analysis, malware classification, or security policy recommendations. 
The model must be regularly updated and retrained with new data as the cyber threat landscape evolves.
