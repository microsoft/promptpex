[LLM FrontEnd][generate_rules_global] generating rules for input: [private]

[LLM FrontEnd][generate_rules_global] generated rules: The output must be specifically tailored to the user's goals as mentioned in the system prompt.
The output must be generated in the format of a dialogue, representing an interactive chat between the user and the LLM.
The output should provide clear and actionable advice or information that assists the user in achieving their mentioned goals.
The output should maintain a polite and professional tone throughout the conversation.
The dialogue must be coherent and logical, ensuring that the conversation flows in a manner that makes sense contextually based on the system prompt.
Any terminology, jargon, or specialized language used in the output must be explained or clarified to ensure understanding by the user.
The output must not include any personal opinions or biases of the LLM; it should remain objective and focused on helping the user.
Each part of the output or dialogue should directly or indirectly relate to or reference the content of the system prompt.
The output should not introduce any new topics or stray from the user's original goals unless it is a direct implication or necessary for the user's understanding.
The LLMâ€™s responses in the output must strictly adhere to factual accuracy and up-to-date information relevant to the user's goals.
