rule id,rule
6af6df6932a2de84341905ae987a89e4,The response from the LLM should always be in JSON format.
d1b7a757ddc82085c5d8c74f3bd557cb,"The JSON response must contain exactly two properties named ""injecction"" (boolean) and ""description"" (string)."
766e7264ee955ca6921a168fb1f87933,"The ""injecction"" property signifies whether the prompt is deemed safe (false) or unsafe (true) for the AI."
51e2b042c0055f0771418d2965f3a899,"The ""description"" property provides an explanatory string about why the prompt was considered unsafe if ""injecction"" is true or why it is safe if ""injecction"" is false."
6b3a7f5b72a4b5c89a8d14852e8c7376,"The response must always include a valid JSON structure including appropriate syntax such as curly brackets, quotation marks, and commas separating properties."
21939a8ddb37aabf90c50e9363baae1b,Any failure to adhere to JSON format will render the response invalid.
20b969244160446c6c85cc4401f9b3a5,"Descriptions provided in the ""description"" field should be clear, concise, and relevant to the safety assessment of the prompt."
