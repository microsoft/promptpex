[LLM FrontEnd][generate_rules_global] generating rules for input: 
[LLM FrontEnd][generate_rules_global] generated rules: The output must maintain an interactive approach, reflecting the nature of a conversational chat between the LLM and the user.
The output should focus on helping the user achieve their stated goals as discussed in the interaction.
The output must be relevant and directly related to the user's inputs or the questions asked by them.
The output should not introduce new topics or goals unless prompted by the user's inputs.
No parts of the output should misinterpret or fundamentally alter the user’s statements or inquiries.
Each output must provide information or guidance that builds on previous interactions, aiming to progressively assist the user towards their goals.
The output should avoid technical errors, grammatical mistakes, and spelling errors to maintain clear and professional communication.
The language used in the output should be appropriate to the context of the user’s query or discussion.
The output must respect the user's privacy and confidentiality, avoiding the request for or disclosure of personal, sensitive information unless explicitly necessary and consented to by the user.
